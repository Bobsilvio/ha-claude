{
  "name": "AI Assistant for Home Assistant",
  "version": "3.0.34",
  "version": "3.0.36",
  "slug": "claude-backend",
  "description": "AI-powered smart home assistant with Claude, ChatGPT, Gemini, NVIDIA NIM and GitHub Models (40+ AI models)",
  "url": "https://github.com/Bobsilvio/ha-claude",
  "init": false,
  "arch": [
    "aarch64",
    "amd64",
    "armv7"
  ],
  "startup": "application",
  "apparmor": false,
  "boot": "auto",
  "ingress": true,
  "ingress_port": 5000,
  "ingress_entry": "/",
  "panel_icon": "mdi:robot",
  "panel_title": "AI Assistant",
  "homeassistant_api": true,
  "map": [
    "config:rw"
  ],
  "ports": {
    "5000/tcp": null
  },
  "ports_description": {
    "5000/tcp": "AI Assistant API"
  },
  "environment": {
    "DEBUG_MODE": "False"
  },
  "options": {
    "ai_provider": "anthropic",
    "ai_model": "Claude: Sonnet 4",
    "anthropic_api_key": "",
    "openai_api_key": "",
    "google_api_key": "",
    "nvidia_api_key": "",
    "nvidia_thinking_mode": false,
    "github_token": "",
    "api_port": "5000",
    "debug_mode": false,
    "enable_file_access": false,
    "language": "en",
    "timeout": "30",
    "max_retries": "3"
  },
  "schema": {
    "ai_provider": "list(anthropic|openai|google|nvidia|github)",
    "ai_model": "list(Claude: Sonnet 4|Claude: Opus 4|Claude: Haiku 4|OpenAI: GPT-4o|OpenAI: GPT-4o-mini|OpenAI: GPT-4-turbo|OpenAI: o1|OpenAI: o3-mini|Google: Gemini 2.0 Flash|Google: Gemini 2.5 Pro|Google: Gemini 2.5 Flash|NVIDIA: Kimi K2.5 ğŸ§ªğŸ†“|NVIDIA: Llama 3.1 70B ğŸ§ªğŸ†“|NVIDIA: Llama 3.1 405B ğŸ§ªğŸ†“|NVIDIA: Mistral Large 2 ğŸ§ªğŸ†“|NVIDIA: Phi-4 ğŸ§ªğŸ†“|NVIDIA: Nemotron 70B ğŸ§ªğŸ†“|GitHub: GPT-4o ğŸ†“|GitHub: GPT-4o-mini ğŸ†“|GitHub: GPT-4.1 ğŸ†“|GitHub: GPT-4.1-mini ğŸ†“|GitHub: GPT-4.1-nano ğŸ†“|GitHub: o1 ğŸ†“|GitHub: o1-mini ğŸ†“|GitHub: o1-preview ğŸ†“|GitHub: o3 ğŸ†“|GitHub: o3-mini ğŸ†“|GitHub: o4-mini ğŸ†“|GitHub: GPT-5 ğŸ†“|GitHub: GPT-5-mini ğŸ†“|GitHub: GPT-5-nano ğŸ†“|GitHub: GPT-5-chat ğŸ†“|GitHub: Llama 3.1 405B ğŸ†“|GitHub: Llama 3.1 8B ğŸ†“|GitHub: Llama 3.3 70B ğŸ†“|GitHub: Llama 4 Scout ğŸ†“|GitHub: Llama 4 Maverick ğŸ†“|GitHub: Mistral Small 2503 ğŸ†“|GitHub: Mistral Medium 2505 ğŸ†“|GitHub: Ministral 3B ğŸ†“|GitHub: Codestral 2501 ğŸ†“|GitHub: Cohere Command R+ ğŸ†“|GitHub: Cohere Command R ğŸ†“|GitHub: Cohere Command A ğŸ†“|GitHub: DeepSeek R1 ğŸ†“|GitHub: DeepSeek R1 0528 ğŸ†“|GitHub: DeepSeek V3 ğŸ†“|GitHub: MAI-DS-R1 ğŸ†“|GitHub: Phi-4 ğŸ†“|GitHub: Phi-4 Mini ğŸ†“|GitHub: Phi-4 Reasoning ğŸ†“|GitHub: Phi-4 Mini Reasoning ğŸ†“|GitHub: Jamba 1.5 Large ğŸ†“|GitHub: Grok-3 ğŸ†“|GitHub: Grok-3 Mini ğŸ†“)?",
    "anthropic_api_key": "password?",
    "openai_api_key": "password?",
    "google_api_key": "password?",
    "nvidia_api_key": "password?",
    "nvidia_thinking_mode": "bool?",
    "github_token": "password?",
    "api_port": "str",
    "debug_mode": "bool?",
    "enable_file_access": "bool?",
    "language": "list(en|it|es|fr)?",
    "timeout": "str?",
    "max_retries": "str?"
  },
  "documentation": "https://github.com/Bobsilvio/ha-claude",
  "support": "https://github.com/Bobsilvio/ha-claude/issues",
  "maintainers": [
    "Bobsilvio"
  ]
}
